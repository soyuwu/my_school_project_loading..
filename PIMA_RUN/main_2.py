# ===============================================
# üéØ M·ª•c ti√™u: Hu·∫•n luy·ªán XGBoost, ƒë√°nh gi√° b·∫±ng ma tr·∫≠n nh·∫ßm l·∫´n
#              v√† t√≠nh th√™m c√°c ch·ªâ s·ªë y h·ªçc: Specificity, PPV, NPV
# ===============================================

# üß∞ Import th∆∞ vi·ªán
import pandas as pd
import numpy as np
from sklearn import model_selection
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
from imblearn.under_sampling import TomekLinks
from imblearn.over_sampling import SMOTE

from xgboost import XGBClassifier
import pre  # module ti·ªÅn x·ª≠ l√Ω

# ===============================================
# 1Ô∏è‚É£ Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu
# ===============================================
X_train, X_test, y_train, y_test = pd.read_csv("C:/NCKH/PIMA_RUN/diab.csv")

# ===============================================
# 2Ô∏è‚É£ C√¢n b·∫±ng d·ªØ li·ªáu b·∫±ng k·ªπ thu·∫≠t TomekLinks
# ===============================================
undersample = TomekLinks()
X_train, y_train = undersample.fit_resample(X_train, y_train)

# ===============================================
# 3Ô∏è‚É£ Hu·∫•n luy·ªán m√¥ h√¨nh XGBoost
# ===============================================
xgb = XGBClassifier( random_state = 42, eval_metric = 'logloss')
#Chia d∆∞ÃÉ li√™Ã£u ƒë√™Ãâ ki√™Ãâm ƒëiÃ£nh cheÃÅo: 
#  - Chia t√¢Ã£p d∆∞ÃÉ li√™Ã£u thaÃÄnh K ph√¢ÃÄn bƒÉÃÄng nhau
#  - LƒÉÃ£p laÃ£i K l√¢ÃÄn, m√¥ÃÉi l√¢ÃÄn 1 fold ƒë√™Ãâ test coÃÄn laÃ£i laÃÄ t√¢Ã£p train
#  - L√¢ÃÅy trung biÃÄnh k√™ÃÅt quaÃâ ƒë√™Ãâ ƒëaÃÅnh giaÃÅ ƒë√¥Ã£ √¥Ãân ƒëiÃ£nh cuÃâa m√¥ hiÃÄnh
# n_split: chia K l√¢ÃÄn
# shuffle: true n√™ÃÅu mu√¥ÃÅn tr√¥Ã£n data ban ƒë√¢ÃÄu

kfold = model_selection.StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)
predictions = model_selection.cross_val_predict(xgb, X_train, y_train, cv=kfold)
xgb.fit(X_train, y_train)
Confu_Matrix = confusion_matrix(y_train, predictions)


# ===============================================
# 4Ô∏è‚É£ Ma tr·∫≠n nh·∫ßm l·∫´n v√† ch·ªâ s·ªë th·ªëng k√™ y h·ªçc
# ===============================================
# n_classes = 2  
# y_true = y_test
# y_pred = predictions

# tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()
# specificity = tn / (tn + fp)
# ppv = tp / (tp + fp) if (tp + fp) > 0 else 0
# npv = tn / (tn + fn) if (tn + fn) > 0 else 0

# print("Specificity:", specificity)
# print("PPV (Precision):", ppv)
# print("NPV:", npv)



#  C√°c ch·ªâ s·ªë c∆° b·∫£n
# acc = accuracy_score(y_test, y_pred)
# pre = precision_score(y_test, y_pred)       # PPV
# rec = recall_score(y_test, y_pred)          # Sensitivity
# f1 = f1_score(y_test, y_pred)
# cm = confusion_matrix(y_test, y_pred)

#  C√°c ch·ªâ s·ªë y h·ªçc
#specificity = TN / (TN + FP)
#ppv = TP / (TP + FP) if (TP + FP) > 0 else 0
#npv = TN / (TN + FN) if (TN + FN) > 0 else 0

# ===============================================
# 5Ô∏è‚É£ In k·∫øt qu·∫£ chi ti·∫øt
# ===============================================
# print(f"Confusion Matrix:\n{cm}\n")
# print(f"Accuracy     : {acc:.4f}")
# print(f"Precision(PPV): {pre:.4f}")
# print(f"Recall (Sens): {rec:.4f}")
# print(f"F1-score     : {f1:.4f}")
#print(f"Specificity  : {specificity:.4f}")
#print(f"NPV          : {npv:.4f}")

# ===============================================
# ‚úÖ Ghi ch√∫:
# - TP: D·ª± ƒëo√°n ƒë√∫ng l·ªõp 1
# - TN: D·ª± ƒëo√°n ƒë√∫ng l·ªõp 0
# - Specificity = TN / (TN + FP)
# - Sensitivity (Recall) = TP / (TP + FN)
# - PPV (Precision) = TP / (TP + FP)
# - NPV = TN / (TN + FN)
# ===============================================
